{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUDwx8yzCrS3"
   },
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpQATvNloQJK"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6560,
     "status": "ok",
     "timestamp": 1606298819752,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "GEvOT3H6oSGh",
    "outputId": "7e95d152-02b5-49a4-ef10-48306f5e3a41"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dataset2020.csv\")\n",
    "mapping = {'pe-legit': 0, 'pe-malicious': 1}\n",
    "data.iloc[:,0].replace(mapping, inplace=True)\n",
    "\n",
    "X=data.iloc[:,1:].values\n",
    "Y=data.iloc[:,0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkezjohqoWtu"
   },
   "source": [
    "# process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6106,
     "status": "ok",
     "timestamp": 1606298831976,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "l3quneC2obvt",
    "outputId": "9b3e54a3-c081-471f-b583-d915889a4b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49128, 2) (49128, 1, 486)\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import *\n",
    "\n",
    "feature=array(X)\n",
    "label=array(Y)\n",
    "label = np.reshape(label, (label.shape[0], 1))\n",
    "label = to_categorical(label, num_classes = 2)\n",
    "\n",
    "arr = []\n",
    "for i in feature:\n",
    "  arr.append(np.reshape(i, (1, 486)).tolist())\n",
    "feature = np.array(arr)\n",
    "\n",
    "print(label.shape, feature.shape)\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9ZQvt6Wol2d"
   },
   "source": [
    "# Split train-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1434,
     "status": "ok",
     "timestamp": 1606298837869,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "Iq5L1OFNosFM",
    "outputId": "71c95da3-832f-4c93-b5f1-0f012cf2aaa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train ,X_test, Y_train,Y_test = train_test_split(feature, label,test_size=1 / 5, random_state=0)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LLo6GiRov-L"
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def f1_score(y_true, y_pred, threshold_shift=0):\n",
    "    beta = 2\n",
    "\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin), axis=1) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)), axis=1)\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = beta ** 2\n",
    "    return K.mean((beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Tanh 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1606308669821,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "aq3wFpv9o3kr",
    "outputId": "aca3cc53-6c3f-4ecc-87c4-1b072118fe68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Tanh 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation tanh 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acitvation tanh 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "662/874 [=====================>........] - ETA: 0s - loss: 0.4104 - accuracy: 0.8138"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-d21e216c7ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m history = model.fit(x=X_train, y=Y_train,batch_size=36,\n\u001b[1;32m---> 19\u001b[1;33m                     epochs=50, validation_split = 0.2, shuffle=True)\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "label_pred = np.argmax(y_pred, axis = -1)\n",
    "label_true = np.argmax(Y_test, axis = -1)\n",
    "matrix = confusion_matrix(label_true, label_pred)\n",
    "print(matrix)\n",
    "print(\"acc : \", accuracy_score(label_true, label_pred))\n",
    "print(\"f1 : \", f1_score(label_true, label_pred, average='macro'))\n",
    "print(\"recall : \", recall_score(label_true, label_pred, average='macro'))\n",
    "print(\"precision : \", precision_score(label_true, label_pred, average='macro'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False)\n",
    "\n",
    "from matplotlib import pyplot\n",
    " \n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()\n",
    " \n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'])\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
