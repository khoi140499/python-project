{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUDwx8yzCrS3"
   },
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpQATvNloQJK"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6560,
     "status": "ok",
     "timestamp": 1606298819752,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "GEvOT3H6oSGh",
    "outputId": "7e95d152-02b5-49a4-ef10-48306f5e3a41"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dataset2020.csv\")\n",
    "mapping = {'pe-legit': 0, 'pe-malicious': 1}\n",
    "data.iloc[:,0].replace(mapping, inplace=True)\n",
    "\n",
    "X=data.iloc[:,1:].values\n",
    "Y=data.iloc[:,0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkezjohqoWtu"
   },
   "source": [
    "# process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6106,
     "status": "ok",
     "timestamp": 1606298831976,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "l3quneC2obvt",
    "outputId": "9b3e54a3-c081-471f-b583-d915889a4b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49128, 2) (49128, 1, 486)\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import *\n",
    "\n",
    "feature=array(X)\n",
    "label=array(Y)\n",
    "label = np.reshape(label, (label.shape[0], 1))\n",
    "label = to_categorical(label, num_classes = 2)\n",
    "\n",
    "arr = []\n",
    "for i in feature:\n",
    "  arr.append(np.reshape(i, (1, 486)).tolist())\n",
    "feature = np.array(arr)\n",
    "\n",
    "print(label.shape, feature.shape)\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9ZQvt6Wol2d"
   },
   "source": [
    "# Split train-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1434,
     "status": "ok",
     "timestamp": 1606298837869,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "Iq5L1OFNosFM",
    "outputId": "71c95da3-832f-4c93-b5f1-0f012cf2aaa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train ,X_test, Y_train,Y_test = train_test_split(feature, label,test_size=1 / 5, random_state=0)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LLo6GiRov-L"
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def f1_score(y_true, y_pred, threshold_shift=0):\n",
    "    beta = 2\n",
    "\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin), axis=1) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)), axis=1)\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = beta ** 2\n",
    "    return K.mean((beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Tanh 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1606308669821,
     "user": {
      "displayName": "Hương Đinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOQjDMoWFuRyUgaVfsUpYDDgjLNtFeXT3NNGwu=s64",
      "userId": "09694898760649833379"
     },
     "user_tz": -420
    },
    "id": "aq3wFpv9o3kr",
    "outputId": "aca3cc53-6c3f-4ecc-87c4-1b072118fe68",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.4095 - accuracy: 0.8173 - f1_score: 0.8174 - precision: 0.7690 - recall: 0.7690 - val_loss: 0.3434 - val_accuracy: 0.8524 - val_f1_score: 0.8522 - val_precision: 0.8211 - val_recall: 0.8211\n",
      "Epoch 2/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.2991 - accuracy: 0.8811 - f1_score: 0.8811 - precision: 0.8382 - recall: 0.8382 - val_loss: 0.2583 - val_accuracy: 0.9057 - val_f1_score: 0.9058 - val_precision: 0.8524 - val_recall: 0.8524\n",
      "Epoch 3/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.2597 - accuracy: 0.9014 - f1_score: 0.9015 - precision: 0.8620 - recall: 0.8620 - val_loss: 0.2997 - val_accuracy: 0.8879 - val_f1_score: 0.8880 - val_precision: 0.8690 - val_recall: 0.8690\n",
      "Epoch 4/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.2340 - accuracy: 0.9116 - f1_score: 0.9117 - precision: 0.8742 - recall: 0.8742 - val_loss: 0.2017 - val_accuracy: 0.9263 - val_f1_score: 0.9263 - val_precision: 0.8797 - val_recall: 0.8797\n",
      "Epoch 5/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.2155 - accuracy: 0.9202 - f1_score: 0.9203 - precision: 0.8844 - recall: 0.8844 - val_loss: 0.2025 - val_accuracy: 0.9248 - val_f1_score: 0.9250 - val_precision: 0.8882 - val_recall: 0.8882\n",
      "Epoch 6/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.2023 - accuracy: 0.9262 - f1_score: 0.9262 - precision: 0.8916 - recall: 0.8916 - val_loss: 0.2076 - val_accuracy: 0.9267 - val_f1_score: 0.9267 - val_precision: 0.8946 - val_recall: 0.8946\n",
      "Epoch 7/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1917 - accuracy: 0.9309 - f1_score: 0.9309 - precision: 0.8974 - recall: 0.8974 - val_loss: 0.1765 - val_accuracy: 0.9368 - val_f1_score: 0.9367 - val_precision: 0.8999 - val_recall: 0.8999\n",
      "Epoch 8/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1814 - accuracy: 0.9346 - f1_score: 0.9346 - precision: 0.9022 - recall: 0.9022 - val_loss: 0.1723 - val_accuracy: 0.9410 - val_f1_score: 0.9411 - val_precision: 0.9044 - val_recall: 0.9044\n",
      "Epoch 9/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1742 - accuracy: 0.9372 - f1_score: 0.9373 - precision: 0.9064 - recall: 0.9064 - val_loss: 0.1674 - val_accuracy: 0.9428 - val_f1_score: 0.9429 - val_precision: 0.9082 - val_recall: 0.9082\n",
      "Epoch 10/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1687 - accuracy: 0.9392 - f1_score: 0.9392 - precision: 0.9099 - recall: 0.9099 - val_loss: 0.1612 - val_accuracy: 0.9403 - val_f1_score: 0.9405 - val_precision: 0.9114 - val_recall: 0.9114\n",
      "Epoch 11/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1623 - accuracy: 0.9420 - f1_score: 0.9421 - precision: 0.9128 - recall: 0.9128 - val_loss: 0.1660 - val_accuracy: 0.9429 - val_f1_score: 0.9428 - val_precision: 0.9142 - val_recall: 0.9142\n",
      "Epoch 12/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1588 - accuracy: 0.9428 - f1_score: 0.9428 - precision: 0.9154 - recall: 0.9154 - val_loss: 0.1708 - val_accuracy: 0.9422 - val_f1_score: 0.9422 - val_precision: 0.9166 - val_recall: 0.9166\n",
      "Epoch 13/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1535 - accuracy: 0.9452 - f1_score: 0.9452 - precision: 0.9177 - recall: 0.9177 - val_loss: 0.1551 - val_accuracy: 0.9480 - val_f1_score: 0.9479 - val_precision: 0.9188 - val_recall: 0.9188\n",
      "Epoch 14/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1487 - accuracy: 0.9468 - f1_score: 0.9469 - precision: 0.9198 - recall: 0.9198 - val_loss: 0.1560 - val_accuracy: 0.9478 - val_f1_score: 0.9478 - val_precision: 0.9208 - val_recall: 0.9208\n",
      "Epoch 15/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1436 - accuracy: 0.9482 - f1_score: 0.9481 - precision: 0.9218 - recall: 0.9218 - val_loss: 0.1526 - val_accuracy: 0.9449 - val_f1_score: 0.9449 - val_precision: 0.9227 - val_recall: 0.9227\n",
      "Epoch 16/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1397 - accuracy: 0.9512 - f1_score: 0.9511 - precision: 0.9235 - recall: 0.9235 - val_loss: 0.1452 - val_accuracy: 0.9484 - val_f1_score: 0.9485 - val_precision: 0.9244 - val_recall: 0.9244\n",
      "Epoch 17/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1354 - accuracy: 0.9513 - f1_score: 0.9513 - precision: 0.9252 - recall: 0.9252 - val_loss: 0.1524 - val_accuracy: 0.9498 - val_f1_score: 0.9497 - val_precision: 0.9260 - val_recall: 0.9260\n",
      "Epoch 18/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1347 - accuracy: 0.9525 - f1_score: 0.9525 - precision: 0.9267 - recall: 0.9267 - val_loss: 0.1393 - val_accuracy: 0.9538 - val_f1_score: 0.9540 - val_precision: 0.9274 - val_recall: 0.9274\n",
      "Epoch 19/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1316 - accuracy: 0.9534 - f1_score: 0.9534 - precision: 0.9282 - recall: 0.9282 - val_loss: 0.1497 - val_accuracy: 0.9515 - val_f1_score: 0.9515 - val_precision: 0.9288 - val_recall: 0.9288\n",
      "Epoch 20/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1282 - accuracy: 0.9545 - f1_score: 0.9545 - precision: 0.9294 - recall: 0.9294 - val_loss: 0.1381 - val_accuracy: 0.9538 - val_f1_score: 0.9540 - val_precision: 0.9301 - val_recall: 0.9301\n",
      "Epoch 21/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1274 - accuracy: 0.9561 - f1_score: 0.9561 - precision: 0.9307 - recall: 0.9307 - val_loss: 0.1326 - val_accuracy: 0.9545 - val_f1_score: 0.9544 - val_precision: 0.9313 - val_recall: 0.9313\n",
      "Epoch 22/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1224 - accuracy: 0.9576 - f1_score: 0.9576 - precision: 0.9319 - recall: 0.9319 - val_loss: 0.1307 - val_accuracy: 0.9553 - val_f1_score: 0.9553 - val_precision: 0.9325 - val_recall: 0.9325\n",
      "Epoch 23/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1230 - accuracy: 0.9570 - f1_score: 0.9570 - precision: 0.9330 - recall: 0.9330 - val_loss: 0.1318 - val_accuracy: 0.9566 - val_f1_score: 0.9567 - val_precision: 0.9335 - val_recall: 0.9335\n",
      "Epoch 24/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1208 - accuracy: 0.9582 - f1_score: 0.9582 - precision: 0.9341 - recall: 0.9341 - val_loss: 0.1418 - val_accuracy: 0.9536 - val_f1_score: 0.9535 - val_precision: 0.9345 - val_recall: 0.9345\n",
      "Epoch 25/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1192 - accuracy: 0.9592 - f1_score: 0.9592 - precision: 0.9350 - recall: 0.9350 - val_loss: 0.1300 - val_accuracy: 0.9566 - val_f1_score: 0.9565 - val_precision: 0.9355 - val_recall: 0.9355\n",
      "Epoch 26/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1164 - accuracy: 0.9604 - f1_score: 0.9603 - precision: 0.9360 - recall: 0.9360 - val_loss: 0.1493 - val_accuracy: 0.9524 - val_f1_score: 0.9523 - val_precision: 0.9364 - val_recall: 0.9364\n",
      "Epoch 27/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1139 - accuracy: 0.9598 - f1_score: 0.9597 - precision: 0.9368 - recall: 0.9368 - val_loss: 0.1500 - val_accuracy: 0.9529 - val_f1_score: 0.9528 - val_precision: 0.9372 - val_recall: 0.9372\n",
      "Epoch 28/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1140 - accuracy: 0.9605 - f1_score: 0.9606 - precision: 0.9376 - recall: 0.9376 - val_loss: 0.1258 - val_accuracy: 0.9567 - val_f1_score: 0.9567 - val_precision: 0.9380 - val_recall: 0.9380\n",
      "Epoch 29/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1104 - accuracy: 0.9626 - f1_score: 0.9626 - precision: 0.9384 - recall: 0.9384 - val_loss: 0.1271 - val_accuracy: 0.9557 - val_f1_score: 0.9556 - val_precision: 0.9388 - val_recall: 0.9388\n",
      "Epoch 30/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1111 - accuracy: 0.9622 - f1_score: 0.9623 - precision: 0.9392 - recall: 0.9392 - val_loss: 0.1328 - val_accuracy: 0.9559 - val_f1_score: 0.9560 - val_precision: 0.9396 - val_recall: 0.9396\n",
      "Epoch 31/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1083 - accuracy: 0.9631 - f1_score: 0.9632 - precision: 0.9399 - recall: 0.9399 - val_loss: 0.1348 - val_accuracy: 0.9585 - val_f1_score: 0.9584 - val_precision: 0.9403 - val_recall: 0.9403\n",
      "Epoch 32/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1077 - accuracy: 0.9632 - f1_score: 0.9632 - precision: 0.9406 - recall: 0.9406 - val_loss: 0.1302 - val_accuracy: 0.9580 - val_f1_score: 0.9579 - val_precision: 0.9410 - val_recall: 0.9410\n",
      "Epoch 33/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1064 - accuracy: 0.9634 - f1_score: 0.9634 - precision: 0.9413 - recall: 0.9413 - val_loss: 0.1300 - val_accuracy: 0.9550 - val_f1_score: 0.9551 - val_precision: 0.9416 - val_recall: 0.9416\n",
      "Epoch 34/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1075 - accuracy: 0.9639 - f1_score: 0.9639 - precision: 0.9419 - recall: 0.9419 - val_loss: 0.1265 - val_accuracy: 0.9580 - val_f1_score: 0.9579 - val_precision: 0.9422 - val_recall: 0.9422\n",
      "Epoch 35/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1057 - accuracy: 0.9640 - f1_score: 0.9640 - precision: 0.9425 - recall: 0.9425 - val_loss: 0.1308 - val_accuracy: 0.9587 - val_f1_score: 0.9588 - val_precision: 0.9428 - val_recall: 0.9428\n",
      "Epoch 36/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1052 - accuracy: 0.9645 - f1_score: 0.9645 - precision: 0.9431 - recall: 0.9431 - val_loss: 0.1273 - val_accuracy: 0.9599 - val_f1_score: 0.9598 - val_precision: 0.9434 - val_recall: 0.9434\n",
      "Epoch 37/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1024 - accuracy: 0.9656 - f1_score: 0.9656 - precision: 0.9437 - recall: 0.9437 - val_loss: 0.1260 - val_accuracy: 0.9587 - val_f1_score: 0.9586 - val_precision: 0.9440 - val_recall: 0.9440\n",
      "Epoch 38/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1011 - accuracy: 0.9652 - f1_score: 0.9652 - precision: 0.9442 - recall: 0.9442 - val_loss: 0.1318 - val_accuracy: 0.9602 - val_f1_score: 0.9603 - val_precision: 0.9445 - val_recall: 0.9445\n",
      "Epoch 39/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.1007 - accuracy: 0.9659 - f1_score: 0.9659 - precision: 0.9448 - recall: 0.9448 - val_loss: 0.1201 - val_accuracy: 0.9604 - val_f1_score: 0.9603 - val_precision: 0.9450 - val_recall: 0.9450\n",
      "Epoch 40/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0987 - accuracy: 0.9673 - f1_score: 0.9674 - precision: 0.9453 - recall: 0.9453 - val_loss: 0.1273 - val_accuracy: 0.9608 - val_f1_score: 0.9607 - val_precision: 0.9455 - val_recall: 0.9455\n",
      "Epoch 41/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0992 - accuracy: 0.9672 - f1_score: 0.9671 - precision: 0.9458 - recall: 0.9458 - val_loss: 0.1254 - val_accuracy: 0.9595 - val_f1_score: 0.9594 - val_precision: 0.9460 - val_recall: 0.9460\n",
      "Epoch 42/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0991 - accuracy: 0.9665 - f1_score: 0.9665 - precision: 0.9463 - recall: 0.9463 - val_loss: 0.1346 - val_accuracy: 0.9615 - val_f1_score: 0.9613 - val_precision: 0.9465 - val_recall: 0.9465\n",
      "Epoch 43/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0994 - accuracy: 0.9676 - f1_score: 0.9677 - precision: 0.9467 - recall: 0.9467 - val_loss: 0.1259 - val_accuracy: 0.9597 - val_f1_score: 0.9596 - val_precision: 0.9470 - val_recall: 0.9470\n",
      "Epoch 44/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0971 - accuracy: 0.9678 - f1_score: 0.9678 - precision: 0.9472 - recall: 0.9472 - val_loss: 0.1316 - val_accuracy: 0.9589 - val_f1_score: 0.9588 - val_precision: 0.9474 - val_recall: 0.9474\n",
      "Epoch 45/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0950 - accuracy: 0.9675 - f1_score: 0.9675 - precision: 0.9476 - recall: 0.9476 - val_loss: 0.1181 - val_accuracy: 0.9615 - val_f1_score: 0.9616 - val_precision: 0.9478 - val_recall: 0.9478\n",
      "Epoch 46/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0948 - accuracy: 0.9686 - f1_score: 0.9686 - precision: 0.9480 - recall: 0.9480 - val_loss: 0.1247 - val_accuracy: 0.9608 - val_f1_score: 0.9607 - val_precision: 0.9482 - val_recall: 0.9482\n",
      "Epoch 47/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0939 - accuracy: 0.9680 - f1_score: 0.9680 - precision: 0.9484 - recall: 0.9484 - val_loss: 0.1346 - val_accuracy: 0.9603 - val_f1_score: 0.9602 - val_precision: 0.9486 - val_recall: 0.9486\n",
      "Epoch 48/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0940 - accuracy: 0.9684 - f1_score: 0.9684 - precision: 0.9488 - recall: 0.9488 - val_loss: 0.1230 - val_accuracy: 0.9594 - val_f1_score: 0.9595 - val_precision: 0.9490 - val_recall: 0.9490\n",
      "Epoch 49/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0912 - accuracy: 0.9706 - f1_score: 0.9707 - precision: 0.9492 - recall: 0.9492 - val_loss: 0.1325 - val_accuracy: 0.9584 - val_f1_score: 0.9583 - val_precision: 0.9494 - val_recall: 0.9494\n",
      "Epoch 50/50\n",
      "874/874 [==============================] - 3s 3ms/step - loss: 0.0919 - accuracy: 0.9694 - f1_score: 0.9694 - precision: 0.9496 - recall: 0.9496 - val_loss: 0.1267 - val_accuracy: 0.9612 - val_f1_score: 0.9613 - val_precision: 0.9498 - val_recall: 0.9498\n",
      "Confusion matrix, without normalization\n",
      "[[4715  185]\n",
      " [ 228 4698]]\n",
      "None\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9605 - f1_score: 0.9606 - precision: 0.9498 - recall: 0.9498\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy', f1_score, Precision(name=\"precision\"), Recall(name=\"recall\")])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import *\n",
    " \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 1ms/step - loss: 0.1377 - accuracy: 0.9580\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Tanh 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation tanh 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acitvation tanh 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "662/874 [=====================>........] - ETA: 0s - loss: 0.4104 - accuracy: 0.8138"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-d21e216c7ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m history = model.fit(x=X_train, y=Y_train,batch_size=36,\n\u001b[1;32m---> 19\u001b[1;33m                     epochs=50, validation_split = 0.2, shuffle=True)\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\khoi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relu 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elu 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selu 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='selu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softsign 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization\n",
    "from keras.metrics import *\n",
    "import keras_metrics as km\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X_train.shape[1:]), return_sequences=False, activation='softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile( loss=\"binary_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,batch_size=36,\n",
    "                    epochs=50, validation_split = 0.2, shuffle=True)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=True,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    "    print(cm)\n",
    " \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "target_names =[\"Legit\",\"Malicious\"]\n",
    "print(plot_confusion_matrix(cm=matrix, classes=target_names, normalize=False))\n",
    "\n",
    "model_val = model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
